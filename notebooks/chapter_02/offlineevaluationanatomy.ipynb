{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommendation Offline Evaluation Example\n",
    "\n",
    "This notebook demonstrates a simplified offline evaluation for a movie recommendation system, focusing on precision as the key metric. We'll build a basic genre-weighted recommendation algorithm and evaluate its precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate or Load Sample Data\n",
    "\n",
    "For this example, we'll generate synthetic data, but in a real application, you would load real user interaction data. \n",
    "\n", 
    "It's worth emphasizing that this sample dataset is extremely simple in an effort to keep the focus on the evaluation concepts rather than the complexity of the data itself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample_data(num_users=50, num_movies=200):\n",
    "    \"\"\"Generate synthetic movie and user interaction data.\"\"\"\n",
    "    \n",
    "    # Create movies with genres\n",
    "    genres = ['Action', 'Comedy', 'Drama', 'Sci-Fi', 'Romance', 'Thriller']\n",
    "    movies = []\n",
    "    \n",
    "    for movie_id in range(1, num_movies + 1):\n",
    "        # Each movie has 1-3 genres\n",
    "        movie_genres = np.random.choice(genres, size=np.random.randint(1, 4), replace=False)\n",
    "        movies.append({\n",
    "            'movie_id': movie_id,\n",
    "            'title': f'Movie {movie_id}',\n",
    "            'genres': '|'.join(movie_genres)\n",
    "        })\n",
    "    \n",
    "    movies_df = pd.DataFrame(movies)\n",
    "    \n",
    "    # Create user interactions\n",
    "    interactions = []\n",
    "    \n",
    "    for user_id in range(1, num_users + 1):\n",
    "        # Each user rates 5-15 movies\n",
    "        num_ratings = np.random.randint(5, 16)\n",
    "        rated_movies = np.random.choice(range(1, num_movies + 1), size=num_ratings, replace=False)\n",
    "        \n",
    "        for movie_id in rated_movies:\n",
    "            interactions.append({\n",
    "                'user_id': user_id,\n",
    "                'movie_id': movie_id,\n",
    "                'rating': np.random.randint(1, 6),  # 1-5 star rating\n",
    "                'timestamp': pd.Timestamp('2023-01-01') + pd.Timedelta(days=np.random.randint(0, 180))\n",
    "            })\n",
    "    \n",
    "    interactions_df = pd.DataFrame(interactions)\n",
    "    \n",
    "    return movies_df, interactions_df\n",
    "\n",
    "# Generate data\n",
    "movies_df, interactions_df = generate_sample_data()\n",
    "\n",
    "# Display sample data\n",
    "print(f\"Generated {len(movies_df)} movies and {len(interactions_df)} user interactions\")\n",
    "print(\"\\nSample movies:\")\n",
    "display(movies_df.head())\n",
    "print(\"\\nSample interactions:\")\n",
    "display(interactions_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Split Data into Training and Testing Sets\n",
    "\n",
    "We'll use a time-based split to simulate a real-world scenario where we train on past data and test on future interactions.\n",
    "\n",
    "By splitting per user and by time, this notebook mimics how a model would actually train (on historical data) and then be evaluated on future behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(interactions, test_ratio=0.2):\n",
    "    \"\"\"Split interaction data into training and testing sets.\"\"\"\n",
    "    # Sort by timestamp\n",
    "    interactions = interactions.sort_values('timestamp')\n",
    "    \n",
    "    # Group by user\n",
    "    user_groups = interactions.groupby('user_id')\n",
    "    \n",
    "    train_data = []\n",
    "    test_data = []\n",
    "    \n",
    "    for _, group in user_groups:\n",
    "        n_items = len(group)\n",
    "        split_idx = int(n_items * (1 - test_ratio))\n",
    "        \n",
    "        # Ensure at least one item in each set\n",
    "        if split_idx == 0:\n",
    "            split_idx = 1\n",
    "        elif split_idx == n_items:\n",
    "            split_idx = n_items - 1\n",
    "        \n",
    "        train_data.append(group.iloc[:split_idx])\n",
    "        test_data.append(group.iloc[split_idx:])\n",
    "    \n",
    "    return pd.concat(train_data).reset_index(drop=True), pd.concat(test_data).reset_index(drop=True)\n",
    "\n",
    "# Split data\n",
    "train_df, test_df = train_test_split(interactions_df)\n",
    "\n",
    "print(f\"Training set: {len(train_df)} interactions\")\n",
    "print(f\"Testing set: {len(test_df)} interactions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Recommendation Algorithm with Genre Weighting\n",
    "\n",
    "We'll implement a simple recommendation algorithm that uses genre preferences to make personalized recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_genre_weights(user_id, train_data, movies_data):\n",
    "    \"\"\"Calculate genre preference weights for a user based on their watching history.\"\"\"\n",
    "    # Get movies the user has watched\n",
    "    user_movies = train_data[train_data['user_id'] == user_id]['movie_id'].tolist()\n",
    "    watched_movies = movies_data[movies_data['movie_id'].isin(user_movies)]\n",
    "    \n",
    "    if watched_movies.empty:\n",
    "        return {}  # Handle cold start case\n",
    "    \n",
    "    # Count genre occurrences\n",
    "    genre_counts = {}\n",
    "    for _, movie in watched_movies.iterrows():\n",
    "        for genre in movie['genres'].split('|'):\n",
    "            genre_counts[genre] = genre_counts.get(genre, 0) + 1\n",
    "    \n",
    "    # Normalize to create weights\n",
    "    total_count = sum(genre_counts.values())\n",
    "    genre_weights = {genre: count/total_count for genre, count in genre_counts.items()}\n",
    "    \n",
    "    return genre_weights\n",
    "\n",
    "def recommend_movies(user_id, train_data, movies_data, top_k=10):\n",
    "    \"\"\"Generate movie recommendations for a user.\"\"\"\n",
    "    # Calculate genre weights\n",
    "    genre_weights = calculate_genre_weights(user_id, train_data, movies_data)\n",
    "    \n",
    "    # Get movies the user has already watched\n",
    "    watched_movies = set(train_data[train_data['user_id'] == user_id]['movie_id'])\n",
    "    \n",
    "    # Score all unwatched movies\n",
    "    recommendations = []\n",
    "    for _, movie in movies_data.iterrows():\n",
    "        if movie['movie_id'] not in watched_movies:\n",
    "            # Calculate relevance score based on genre weights\n",
    "            score = 0\n",
    "            for genre in movie['genres'].split('|'):\n",
    "                score += genre_weights.get(genre, 0)\n",
    "            \n",
    "            recommendations.append((movie['movie_id'], score))\n",
    "    \n",
    "    # Sort by score and return top-k\n",
    "    recommendations.sort(key=lambda x: x[1], reverse=True)\n",
    "    return recommendations[:top_k]\n",
    "\n",
    "# Example recommendation for the first user\n",
    "user_id = interactions_df['user_id'].min()\n",
    "recommendations = recommend_movies(user_id, train_df, movies_df, top_k=5)\n",
    "\n",
    "print(f\"Top 5 recommendations for User {user_id}:\")\n",
    "for movie_id, score in recommendations:\n",
    "    title = movies_df[movies_df['movie_id'] == movie_id]['title'].values[0]\n",
    "    genres = movies_df[movies_df['movie_id'] == movie_id]['genres'].values[0]\n",
    "    print(f\"  {title} (Genres: {genres}) - Score: {score:.3f}\")"
   ]
  },
  {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
     "## 5. Evaluate Precision\n",
     "\n",
     "Now we'll evaluate the precision of our recommendations. Precision measures the fraction of recommended items that are relevant to the user.\n",
     "\n",
     "We'll use **Precision@k**, which looks at the top *k* recommendations. The formula is:\n",
     "\n",
     "$$\\text{Precision@k} = \\frac{|\\text{Recommended Items}_{k} \\cap \\text{Relevant Items}|}{k}$$\n",
     "\n",
     "Where:\n",
     "- **Recommended Itemsₖ** – the top *k* items the model recommended to the user  \n",
     "- **Relevant Items** – the items in the user’s test set (the items they actually interacted with)  \n",
     "- **k** – the number of recommendations we’re evaluating  \n",
     "\n",
     "In plain terms: **Precision@k is the fraction of the top-k recommended items that the user actually found relevant.**"
    ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_precision_at_k(user_id, test_data, recommendations, k=10):\n",
    "    \"\"\"Calculate precision@k for a single user.\"\"\"\n",
    "    # Get actual movies the user interacted with in the test set\n",
    "    actual_movies = set(test_data[test_data['user_id'] == user_id]['movie_id'])\n",
    "    \n",
    "    if not actual_movies:\n",
    "        return None  # No test data for this user\n",
    "    \n",
    "    # Get top-k recommended movies\n",
    "    recommended_movies = [movie_id for movie_id, _ in recommendations[:k]]\n",
    "    \n",
    "    # Calculate precision: number of hits divided by k\n",
    "    hits = len(set(recommended_movies) & actual_movies)\n",
    "    precision = hits / min(k, len(recommended_movies)) if recommended_movies else 0\n",
    "    \n",
    "    return precision\n",
    "\n",
    "def evaluate_model(train_data, test_data, movies_data, k_values=[5, 10]):\n",
    "    \"\"\"Evaluate model precision for multiple k values.\"\"\"\n",
    "    # Get unique users in test data\n",
    "    test_users = test_data['user_id'].unique()\n",
    "    \n",
    "    # Track precision for each k value\n",
    "    results = {f\"precision@{k}\": [] for k in k_values}\n",
    "    \n",
    "    # Evaluate for each user\n",
    "    for user_id in test_users:\n",
    "        # Generate recommendations\n",
    "        recommendations = recommend_movies(user_id, train_data, movies_data, \n",
    "                                          top_k=max(k_values))\n",
    "        \n",
    "        # Calculate precision for each k\n",
    "        for k in k_values:\n",
    "            precision = calculate_precision_at_k(user_id, test_data, recommendations, k)\n",
    "            if precision is not None:\n",
    "                results[f\"precision@{k}\"].append(precision)\n",
    "    \n",
    "    # Calculate average precision for each k\n",
    "    avg_results = {}\n",
    "    for k in k_values:\n",
    "        key = f\"precision@{k}\"\n",
    "        avg_results[key] = sum(results[key]) / len(results[key]) if results[key] else 0\n",
    "    \n",
    "    return avg_results\n",
    "\n",
    "# Evaluate model\n",
    "precision_results = evaluate_model(train_df, test_df, movies_df, k_values=[5, 10])\n",
    "\n",
    "print(\"Evaluation Results:\")\n",
    "for metric, value in precision_results.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Results\n",
    "\n",
    "Let's visualize our precision results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_results(results):\n",
    "    \"\"\"Plot precision results.\"\"\"\n",
    "    metrics = list(results.keys())\n",
    "    values = list(results.values())\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(metrics, values, color='skyblue')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, height + 0.01,\n",
    "                f'{height:.4f}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.title('Precision at Different K Values')\n",
    "    plt.xlabel('Metric')\n",
    "    plt.ylabel('Value')\n",
    "    plt.ylim(0, max(values) * 1.2)  # Add some space for labels\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot results\n",
    "plot_precision_results(precision_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Experiment with Different Genre Weight Multipliers\n",
    "\n",
    "Let's experiment with increasing the importance of genre weights to see if it improves precision. 
    When you run this test cell you'll see a flat line on the plot (and identical printed values) which confirms that changing the multiplier had no effect on the model’s performance in this test.  This is partly because the toy dataset and algorithm are too limited—there isn’t enough diversity for the multiplier to shift recommendations. 
    In a richer dataset or a more sophisticated recommender, you’d expect to see the multiplier affect which items get recommended, and potentially improve precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_with_enhanced_genre_weights(user_id, train_data, movies_data, genre_multiplier=2.0, top_k=10):\n",
    "    \"\"\"Generate recommendations with enhanced genre weights.\"\"\"\n",
    "    # Get basic genre weights\n",
    "    genre_weights = calculate_genre_weights(user_id, train_data, movies_data)\n",
    "    \n",
    "    # Enhance the importance of genre preferences\n",
    "    enhanced_weights = {genre: weight * genre_multiplier for genre, weight in genre_weights.items()}\n",
    "    \n",
    "    # Get movies the user has already watched\n",
    "    watched_movies = set(train_data[train_data['user_id'] == user_id]['movie_id'])\n",
    "    \n",
    "    # Score all unwatched movies\n",
    "    recommendations = []\n",
    "    for _, movie in movies_data.iterrows():\n",
    "        if movie['movie_id'] not in watched_movies:\n",
    "            # Calculate score\n",
    "            score = 0\n",
    "            for genre in movie['genres'].split('|'):\n",
    "                score += enhanced_weights.get(genre, 0)\n",
    "            \n",
    "            recommendations.append((movie['movie_id'], score))\n",
    "    \n",
    "    # Sort by score and return top-k\n",
    "    recommendations.sort(key=lambda x: x[1], reverse=True)\n",
    "    return recommendations[:top_k]\n",
    "\n",
    "def evaluate_with_multiplier(train_data, test_data, movies_data, multiplier, k=10):\n",
    "    \"\"\"Evaluate model with a specific genre weight multiplier.\"\"\"\n",
    "    test_users = test_data['user_id'].unique()\n",
    "    precision_scores = []\n",
    "    \n",
    "    for user_id in test_users:\n",
    "        # Generate enhanced recommendations\n",
    "        recommendations = recommend_with_enhanced_genre_weights(\n",
    "            user_id, train_data, movies_data, genre_multiplier=multiplier, top_k=k)\n",
    "        \n",
    "        # Calculate precision\n",
    "        precision = calculate_precision_at_k(user_id, test_data, recommendations, k)\n",
    "        if precision is not None:\n",
    "            precision_scores.append(precision)\n",
    "    \n",
    "    avg_precision = sum(precision_scores) / len(precision_scores) if precision_scores else 0\n",
    "    return avg_precision\n",
    "\n",
    "# Try different multipliers\n",
    "multipliers = [0.5, 1.0, 1.5, 2.0, 2.5, 3.0]\n",
    "k = 10  # Fix k for this experiment\n",
    "\n",
    "multiplier_results = []\n",
    "for multiplier in multipliers:\n",
    "    precision = evaluate_with_multiplier(train_df, test_df, movies_df, multiplier, k=k)\n",
    "    multiplier_results.append(precision)\n",
    "    print(f\"Genre multiplier {multiplier:.1f} - Precision@{k}: {precision:.4f}\")\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(multipliers, multiplier_results, 'o-', linewidth=2, markersize=8)\n",
    "plt.xlabel('Genre Weight Multiplier')\n",
    "plt.ylabel(f'Precision@{k}')\n",
    "plt.title(f'Effect of Genre Weight Enhancement on Precision@{k}')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary\n",
    "\n",
    "In this notebook, we've demonstrated a simplified offline evaluation for a movie recommendation system. We built a basic genre-weighted recommendation algorithm and evaluated its precision. The key findings are:\n",
    "\n",
    "1. The base model achieved a precision@k of [value from results]\n",
    "2. Enhancing genre weights [improved/worsened] precision, with the optimal multiplier around [best multiplier value]\n",
    "\n",
    "This demonstrates the core offline evaluation concept from Chapter 2, showing how we can:\n",
    "- Use historical data (input) to test recommendation algorithms\n",
    "- Create a structured evaluation process (design)\n",
    "- Measure performance with precision metrics (output)\n",
    "\n",
    "In practice, precision is just one piece of the puzzle. Before moving to an A/B test with real users, you’d run a suite of offline evaluations to check for things like fairness, robustness, and catch unintended behavior.\n",
     "\n",
    "In other words, this single evaluation wouldn’t greenlight an A/B test, but it does illustrate the type of evaluations that helps you build confidence in a model’s behavior."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

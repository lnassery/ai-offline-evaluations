{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counterfactual Evaluation: Off-Policy Evaluation and Incremental Action Value\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. **Off-Policy Evaluation (OPE)** - Section 5.4.2\n",
    "2. **Incremental Action Value** - Section 5.4.3\n",
    "\n",
    "Using a movie recommendation system example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [12, 6]\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Synthetic Logged Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieRecommendationLogger:\n",
    "    def __init__(self, num_users=300, num_movies=20, num_sessions=1000):\n",
    "        self.num_users = num_users\n",
    "        self.num_movies = num_movies\n",
    "        self.num_sessions = num_sessions\n",
    "        \n",
    "        self.movies = self._generate_movies()\n",
    "        self.users = self._generate_users()\n",
    "        self.logged_data = self._generate_logged_data()\n",
    "    \n",
    "    def _generate_movies(self):\n",
    "        genres = ['Action', 'Comedy', 'Drama', 'Horror', 'Romance', 'Sci-Fi']\n",
    "        movies = []\n",
    "        for i in range(self.num_movies):\n",
    "            movie = {\n",
    "                'movie_id': i,\n",
    "                'title': f'Movie_{i}',\n",
    "                'genre': np.random.choice(genres),\n",
    "                'rating': np.random.uniform(3.0, 9.0),\n",
    "                'popularity': np.random.exponential(1)\n",
    "            }\n",
    "            movies.append(movie)\n",
    "        return pd.DataFrame(movies)\n",
    "    \n",
    "    def _generate_users(self):\n",
    "        genres = self.movies['genre'].unique()\n",
    "        users = []\n",
    "        for i in range(self.num_users):\n",
    "            preferred_genres = np.random.choice(genres, size=np.random.randint(1, 3), replace=False)\n",
    "            user = {\n",
    "                'user_id': i,\n",
    "                'preferred_genres': list(preferred_genres),\n",
    "                'engagement_level': np.random.uniform(0.2, 1.0)\n",
    "            }\n",
    "            users.append(user)\n",
    "        return pd.DataFrame(users)\n",
    "    \n",
    "    def _calculate_affinity(self, user_row, movie_row):\n",
    "        base_affinity = 0.3\n",
    "        if movie_row['genre'] in user_row['preferred_genres']:\n",
    "            base_affinity += 0.4\n",
    "        rating_boost = (movie_row['rating'] - 5.0) / 10.0\n",
    "        base_affinity += rating_boost * 0.3\n",
    "        base_affinity *= user_row['engagement_level']\n",
    "        return np.clip(base_affinity, 0.0, 1.0)\n",
    "    \n",
    "    def _logged_policy_probabilities(self, user_row, available_movies):\n",
    "        scores = []\n",
    "        for _, movie in available_movies.iterrows():\n",
    "            score = movie['popularity']\n",
    "            if movie['genre'] in user_row['preferred_genres']:\n",
    "                score *= 1.5\n",
    "            scores.append(score)\n",
    "        \n",
    "        scores = np.array(scores)\n",
    "        exp_scores = np.exp(scores - np.max(scores))\n",
    "        return exp_scores / np.sum(exp_scores)\n",
    "    \n",
    "    def _generate_logged_data(self):\n",
    "        logged_sessions = []\n",
    "        \n",
    "        for session_id in range(self.num_sessions):\n",
    "            user_id = np.random.randint(0, self.num_users)\n",
    "            user_row = self.users.iloc[user_id]\n",
    "            \n",
    "            context = {\n",
    "                'time_of_day': np.random.choice(['morning', 'afternoon', 'evening', 'night']),\n",
    "                'device': np.random.choice(['mobile', 'desktop', 'tv'])\n",
    "            }\n",
    "            \n",
    "            num_available = np.random.randint(5, 10)\n",
    "            available_movie_indices = np.random.choice(self.num_movies, size=num_available, replace=False)\n",
    "            available_movies = self.movies.iloc[available_movie_indices]\n",
    "            \n",
    "            action_probs = self._logged_policy_probabilities(user_row, available_movies)\n",
    "            \n",
    "            chosen_idx = np.random.choice(len(available_movies), p=action_probs)\n",
    "            chosen_movie = available_movies.iloc[chosen_idx]\n",
    "            chosen_prob = action_probs[chosen_idx]\n",
    "            \n",
    "            affinity = self._calculate_affinity(user_row, chosen_movie)\n",
    "            \n",
    "            clicked = np.random.random() < affinity\n",
    "            watch_time = np.random.exponential(affinity * 120) if clicked else 0\n",
    "            \n",
    "            session_data = {\n",
    "                'session_id': session_id,\n",
    "                'user_id': user_id,\n",
    "                'context_time': context['time_of_day'],\n",
    "                'context_device': context['device'],\n",
    "                'recommended_movie_id': chosen_movie['movie_id'],\n",
    "                'action_probability': chosen_prob,\n",
    "                'available_movies': list(available_movies['movie_id']),\n",
    "                'clicked': clicked,\n",
    "                'watch_time': watch_time,\n",
    "                'true_affinity': affinity\n",
    "            }\n",
    "            \n",
    "            logged_sessions.append(session_data)\n",
    "        \n",
    "        return pd.DataFrame(logged_sessions)\n",
    "\n",
    "# Generate dataset\n",
    "logger = MovieRecommendationLogger()\n",
    "logged_data = logger.logged_data\n",
    "movies_catalog = logger.movies\n",
    "users_catalog = logger.users\n",
    "\n",
    "print(f\"Generated {len(logged_data)} sessions\")\n",
    "print(f\"Click-through rate: {logged_data['clicked'].mean():.3f}\")\n",
    "print(f\"Average watch time: {logged_data['watch_time'].mean():.1f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Off-Policy Evaluation (OPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OffPolicyEvaluator:\n",
    "    def __init__(self, logged_data, movies_catalog, users_catalog):\n",
    "        self.logged_data = logged_data\n",
    "        self.movies_catalog = movies_catalog\n",
    "        self.users_catalog = users_catalog\n",
    "    \n",
    "    def new_policy_probabilities(self, user_id, available_movie_ids):\n",
    "        \"\"\"Quality-focused policy (vs popularity-based logged policy)\"\"\"\n",
    "        user_prefs = self.users_catalog.iloc[user_id]['preferred_genres']\n",
    "        available_movies = self.movies_catalog[self.movies_catalog['movie_id'].isin(available_movie_ids)]\n",
    "        \n",
    "        scores = []\n",
    "        for _, movie in available_movies.iterrows():\n",
    "            score = movie['rating']  # Focus on quality\n",
    "            if movie['genre'] in user_prefs:\n",
    "                score *= 2.0  # Strong preference boost\n",
    "            scores.append(score)\n",
    "        \n",
    "        scores = np.array(scores)\n",
    "        if len(scores) == 0:\n",
    "            return np.array([])\n",
    "        \n",
    "        exp_scores = np.exp(scores - np.max(scores))\n",
    "        return exp_scores / np.sum(exp_scores)\n",
    "    \n",
    "    def calculate_importance_weights(self):\n",
    "        weights = []\n",
    "        for _, session in self.logged_data.iterrows():\n",
    "            new_probs = self.new_policy_probabilities(session['user_id'], session['available_movies'])\n",
    "            \n",
    "            if len(new_probs) == 0:\n",
    "                weights.append(0)\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                action_idx = session['available_movies'].index(session['recommended_movie_id'])\n",
    "                new_policy_prob = new_probs[action_idx]\n",
    "                logged_policy_prob = session['action_probability']\n",
    "                \n",
    "                weight = new_policy_prob / logged_policy_prob if logged_policy_prob > 0 else 0\n",
    "            except (ValueError, IndexError):\n",
    "                weight = 0\n",
    "            \n",
    "            weights.append(weight)\n",
    "        \n",
    "        return np.array(weights)\n",
    "    \n",
    "    def evaluate_policy(self, metric='engagement_score'):\n",
    "        weights = self.calculate_importance_weights()\n",
    "        \n",
    "        if metric == 'click_rate':\n",
    "            rewards = self.logged_data['clicked'].astype(float)\n",
    "        elif metric == 'watch_time':\n",
    "            rewards = self.logged_data['watch_time']\n",
    "        else:  # engagement_score\n",
    "            rewards = (self.logged_data['clicked'].astype(float) + self.logged_data['watch_time'] / 100)\n",
    "        \n",
    "        new_policy_value = np.sum(weights * rewards) / np.sum(weights) if np.sum(weights) > 0 else 0\n",
    "        original_policy_value = np.mean(rewards)\n",
    "        \n",
    "        return {\n",
    "            'original_policy_value': original_policy_value,\n",
    "            'new_policy_value': new_policy_value,\n",
    "            'improvement': new_policy_value - original_policy_value,\n",
    "            'relative_improvement': ((new_policy_value / original_policy_value - 1) * 100 if original_policy_value > 0 else 0),\n",
    "            'effective_sample_size': (np.sum(weights) ** 2) / np.sum(weights ** 2) if np.sum(weights) > 0 else 0\n",
    "        }\n",
    "\n",
    "# Evaluate new policy\n",
    "ope_evaluator = OffPolicyEvaluator(logged_data, movies_catalog, users_catalog)\n",
    "result = ope_evaluator.evaluate_policy('engagement_score')\n",
    "\n",
    "print(\"OFF-POLICY EVALUATION RESULTS:\")\n",
    "print(f\"Original Policy Value: {result['original_policy_value']:.4f}\")\n",
    "print(f\"New Policy Value: {result['new_policy_value']:.4f}\")\n",
    "print(f\"Improvement: {result['improvement']:.4f} ({result['relative_improvement']:.1f}%)\")\n",
    "print(f\"Effective Sample Size: {result['effective_sample_size']:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize OPE results\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Policy comparison\n",
    "policies = ['Original', 'New']\n",
    "values = [result['original_policy_value'], result['new_policy_value']]\n",
    "ax1.bar(policies, values, alpha=0.7, color=['blue', 'green'])\n",
    "ax1.set_ylabel('Policy Value')\n",
    "ax1.set_title('Policy Value Comparison')\n",
    "\n",
    "# Importance weights distribution\n",
    "weights = ope_evaluator.calculate_importance_weights()\n",
    "ax2.hist(weights, bins=30, alpha=0.7, edgecolor='black')\n",
    "ax2.axvline(x=np.mean(weights), color='red', linestyle='--', label=f'Mean: {np.mean(weights):.3f}')\n",
    "ax2.set_xlabel('Importance Weight')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.set_title('Distribution of Importance Weights')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Incremental Action Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IncrementalActionValueAnalyzer:\n",
    "    def __init__(self, logged_data, movies_catalog, users_catalog):\n",
    "        self.logged_data = logged_data\n",
    "        self.movies_catalog = movies_catalog\n",
    "        self.users_catalog = users_catalog\n",
    "    \n",
    "    def estimate_counterfactual_outcome(self, user_id, movie_id, context=None):\n",
    "        user_prefs = self.users_catalog.iloc[user_id]['preferred_genres']\n",
    "        user_engagement = self.users_catalog.iloc[user_id]['engagement_level']\n",
    "        movie = self.movies_catalog[self.movies_catalog['movie_id'] == movie_id].iloc[0]\n",
    "        \n",
    "        base_affinity = 0.3\n",
    "        if movie['genre'] in user_prefs:\n",
    "            base_affinity += 0.4\n",
    "        \n",
    "        rating_boost = (movie['rating'] - 5.0) / 10.0\n",
    "        base_affinity += rating_boost * 0.3\n",
    "        base_affinity *= user_engagement\n",
    "        \n",
    "        if context and context.get('time_of_day') == 'evening' and movie['genre'] in ['Horror']:\n",
    "            base_affinity *= 1.2\n",
    "        \n",
    "        affinity = np.clip(base_affinity, 0.0, 1.0)\n",
    "        \n",
    "        return {\n",
    "            'prob_click': affinity,\n",
    "            'expected_watch_time': affinity * 120\n",
    "        }\n",
    "    \n",
    "    def calculate_incremental_values(self, sample_size=300):\n",
    "        sample_sessions = self.logged_data.sample(n=min(sample_size, len(self.logged_data)))\n",
    "        incremental_results = []\n",
    "        \n",
    "        for _, session in sample_sessions.iterrows():\n",
    "            user_id = session['user_id']\n",
    "            recommended_movie = session['recommended_movie_id']\n",
    "            available_movies = session['available_movies']\n",
    "            \n",
    "            context = {\n",
    "                'time_of_day': session['context_time'],\n",
    "                'device': session['context_device']\n",
    "            }\n",
    "            \n",
    "            recommended_estimate = self.estimate_counterfactual_outcome(user_id, recommended_movie, context)\n",
    "            \n",
    "            best_alternative = None\n",
    "            best_alternative_value = 0\n",
    "            best_alternative_estimate = None\n",
    "            \n",
    "            for alt_movie_id in available_movies:\n",
    "                if alt_movie_id != recommended_movie:\n",
    "                    alt_estimate = self.estimate_counterfactual_outcome(user_id, alt_movie_id, context)\n",
    "                    if alt_estimate['expected_watch_time'] > best_alternative_value:\n",
    "                        best_alternative = alt_movie_id\n",
    "                        best_alternative_value = alt_estimate['expected_watch_time']\n",
    "                        best_alternative_estimate = alt_estimate\n",
    "            \n",
    "            if best_alternative is not None:\n",
    "                incremental_click = (best_alternative_estimate['prob_click'] - recommended_estimate['prob_click'])\n",
    "                incremental_watch_time = (best_alternative_estimate['expected_watch_time'] - recommended_estimate['expected_watch_time'])\n",
    "                incremental_engagement = incremental_click + (incremental_watch_time / 100)\n",
    "                \n",
    "                result = {\n",
    "                    'session_id': session['session_id'],\n",
    "                    'recommended_movie': recommended_movie,\n",
    "                    'best_alternative': best_alternative,\n",
    "                    'actual_clicked': session['clicked'],\n",
    "                    'actual_watch_time': session['watch_time'],\n",
    "                    'incremental_engagement': incremental_engagement,\n",
    "                    'context_time': context['time_of_day'],\n",
    "                    'context_device': context['device']\n",
    "                }\n",
    "                incremental_results.append(result)\n",
    "        \n",
    "        return pd.DataFrame(incremental_results)\n",
    "\n",
    "# Analyze incremental values\n",
    "iav_analyzer = IncrementalActionValueAnalyzer(logged_data, movies_catalog, users_catalog)\n",
    "incremental_results = iav_analyzer.calculate_incremental_values()\n",
    "\n",
    "print(\"INCREMENTAL ACTION VALUE RESULTS:\")\n",
    "print(f\"Analyzed {len(incremental_results)} sessions\")\n",
    "print(f\"Average incremental engagement: {incremental_results['incremental_engagement'].mean():.4f}\")\n",
    "print(f\"Sessions with positive incremental value: {(incremental_results['incremental_engagement'] > 0).mean() * 100:.1f}%\")\n",
    "print(f\"Maximum potential gain: {incremental_results['incremental_engagement'].max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize incremental results\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Distribution of incremental values\n",
    "ax1.hist(incremental_results['incremental_engagement'], bins=30, alpha=0.7, edgecolor='black')\n",
    "ax1.axvline(x=0, color='red', linestyle='--', label='No improvement')\n",
    "ax1.axvline(x=incremental_results['incremental_engagement'].mean(), \n",
    "           color='green', linestyle='--', label=f'Mean: {incremental_results[\"incremental_engagement\"].mean():.3f}')\n",
    "ax1.set_xlabel('Incremental Engagement Value')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_title('Distribution of Incremental Values')\n",
    "ax1.legend()\n",
    "\n",
    "# By time of day\n",
    "time_groups = incremental_results.groupby('context_time')['incremental_engagement'].mean()\n",
    "ax2.bar(time_groups.index, time_groups.values, alpha=0.7)\n",
    "ax2.set_xlabel('Time of Day')\n",
    "ax2.set_ylabel('Mean Incremental Engagement')\n",
    "ax2.set_title('Incremental Value by Time of Day')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show top opportunities\n",
    "print(\"TOP 5 IMPROVEMENT OPPORTUNITIES:\")\n",
    "top_opportunities = incremental_results.nlargest(5, 'incremental_engagement')\n",
    "\n",
    "for i, (_, opp) in enumerate(top_opportunities.iterrows(), 1):\n",
    "    rec_movie = movies_catalog[movies_catalog['movie_id'] == opp['recommended_movie']].iloc[0]\n",
    "    alt_movie = movies_catalog[movies_catalog['movie_id'] == opp['best_alternative']].iloc[0]\n",
    "    \n",
    "    print(f\"{i}. Session {opp['session_id']}:\")\n",
    "    print(f\"   Recommended: {rec_movie['genre']} (Rating: {rec_movie['rating']:.1f})\")\n",
    "    print(f\"   Alternative: {alt_movie['genre']} (Rating: {alt_movie['rating']:.1f})\")\n",
    "    print(f\"   Potential gain: {opp['incremental_engagement']:.3f}\")\n",
    "    print(f\"   Context: {opp['context_time']} on {opp['context_device']}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
